---
title: "Coursera Data Analytics Capstone Project"
author: "Kacie Morinaga"
output:
  html_document: default
  pdf_document: default
date: "`r Sys.Date()`"
---

This R notebook explains my process for the case study for the Coursera Data Analytics Capstone project in the Data Analytics Certificate Course. 

This case study will be processed using Google's Data Analytics 6 steps: Ask, Prepare, Process, Analyze, Share, and Act. 


# Step 1: Ask
In the first step, the purpose of this case study will be explained along with the objectives of the data analysis.

### 1.0 Introduction
Bellabeat is a small, but successful high-tech manufacturer of health-focused products for women. They are looking to expand into the smart device arena to grow their business. As a new junior data analyst you have been asked to examine smart device usage data to gain insight into how consumers are using their smart devices and use these insights to guide marketing initiatives. 

### 1.1 Identify the business task
The business task is to identify trends in smart device usage to guide marketing strategy initiatives for Bellabeat

### 1.2 Key Stakeholders
  +   Urška Sršen: Bellabeat's cofounder and Chief Creative Officer
  +   Sando Mur: Mathematician and Bellabeat's cofounder; key member of the Bellabeat executive team
  +   Bellabeat marketing analytics team: a team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat's marketing strategy

# Step 2: Prepare
In this step, we identify the data we are using and organize it to make it useful. I decided to use R to perform my data analysis. 

### 2.0 Information about the dataset
1. The dataset is stored online, available [here](https://www.kaggle.com/datasets/arashnic/fitbit) on Kaggle.com, which is an online community platform for data scientists and machine learning enthusiasts.
2. The dataset is organized into 18 csv files. Generally, it is in long format, but there are wide versions of some of the files. The files I have chosen to use for my analysis are dailyActivity_merged.csv and sleepDay_merged.csv, which are both in long format.
3. Bias and credibility of the dataset 
    + There are bias and credibility issues with the data because it was collected from 30 FitBit users, which is not reflective of the population of potential Bellabeat customers or the population in general. Additionally it was compiled by a third party so the credibility of the data is questionable
    + Does the data ROCCC?
      -   Reliability LOW - The eligibility of the study participants is not specifically established, and the subjects’ demographics are unknown. This can affect the outcome of the analysis because Bellabeat is a female focused company. Additionally, the test group is small at 30 participants, which is again not representative of the general female population.
      -   Original LOW – the source of the data is from a third party.
      -   Comprehensive MED – there are several variables collected, including calories burned, daily steps, distance, active minutes, sleep minutes. 
      -   Current LOW - the data is not up to date because it was collected from 3.12.2016 to 5.12.2016, over six years ago.
      -   Cited LOW - data collected from a third party.
4.  Licensing, privacy, security, and accessibility - The dataset is public and the creator waived all rights to their work worldwide under copyright law. Therefore, everyone is allowed to copy, modify, distribute, and perform the work.   
5.  Data integrity - Because the data is from a third-party, its accuracy cannot be guaranteed. Upon initial glimpse, it is difficult to determine whether or not it is complete, but that can be determined upon further examination. The quality of the data is on the lower end, as determined by looking at the ROCCC scores. 
6.  The data can help answer our business task because it gives us two month's information of activity tracking using a smart device from 30 users. By analyzing the data, we may be able to find activity and usage trends to improve appeal of these smart devices to potential customers.


### 2.1 Key Tasks

#### 2.1.1 Download the data and store it appropriately
I downloaded the dataset from [here](https://www.kaggle.com/datasets/arashnic/fitbit) on Kaggle.com, and created a folder on my computer to keep the raw data files, labeling each appropriately.

#### 2.1.2 Identify how it is organized
I decided to use R to perform my data analysis. In order to identify how it is organized, I needed to import it to R. First, I have to set up my environment.

##### Setting up my environment
I've chosen to load the entire tidyverse. It generally contains all the packages I will need for analysis. If I come across another package I need in the future, I can load it at that time.
```{r Loading packages}
library(tidyverse)
```

##### Importing our data
I've downloaded the dataset to my computer as a csv file from kaggle.com. I can import it into R using readr, which was in the tidyverse package. I've chosen to use the dailyActivity_merged and sleepDay_merged dataframes. 
```{r Using readr to import dataset}
daily_activity <-read_csv("Desktop/Desktop - MacBook Air/FitBit raw data/dailyActivity_merged.csv")
sleep_day <- read_csv("Desktop/Desktop - MacBook Air/FitBit raw data/sleepDay_merged.csv")
```
As I imported the data, I changed the names of the dataframes to a consistent format, using only lowercase letters and underscores in place of spaces. 

It is revealed that there are 940 rows with 15 columns in the daily_activity dataframe. There are 413 rows with 5 columns in the sleep_day dataframe. This is important to note because it seems that there is more than double the data available for daily activity vs. sleeping. 

### 2.2 Previewing the data

##### 2.2.1 The glimpse function
The glimpse function allows you to see the titles of all of the columns of your dataset and lists the first few variables of each.
```{r Using glimpse}
glimpse(daily_activity)
glimpse(sleep_day)
```

Using glimpse on the dataframes reveals that both have an Id column and followed by a date column, although in daily_activity it is "ActivityDate" and in sleep_day it is "SleepDay". Additionally, the SleepDay data also has a time component. 

##### 2.2.2 The str function
The str function shows the structure of the dataset. We can use it to examine both datasets. 
```{r Using str}
str(daily_activity)
str(sleep_day)
```

Of note is that the date in both dataframes is formatted as characters, rather than dates. This will be converted later in the cleaning process.

##### 2.2.3 Looking for null values
Knowing if and how many null values will tell me if there is missing data. I decided to look at the dataframes separately so I would know if there was already data missing, and which dataframe is missing information. 

```{r Looking for null values in the two dataframes}
sum(is.na(daily_activity))
sum(is.na(sleep_day))
```
Now we know that both tables do not have null values when examined on their own. 

### 2.3 Sorting and filtering the data
So far, the data seems to be in a decent order in both dataframes. It is sorted first by Id, then by date and then shows all the variables collected for the listed subject on the specified date. As mentioned previously there are some changes to be made, but they can be done during the cleaning process.  

### 2.4 Renaming the dataframe columns
Following the standardized format used to rename the dataframes, I have also decided to rename all the columns using all lowercase letters and underscores to mark the spaces between words. However, I will have to install and load the janitor package to use the clean_names function.

```{r Loading janitor package}
library(janitor)
```

Once I have installed the janitor package I can use the clean_names function to rename the columns. 
```{r Renaming the dataframe and cleaning the column names}
daily_activity <- clean_names(daily_activity)
sleep_day <- clean_names(sleep_day)
```

Running glimpse again will show the changes.
```{r View changes made with renaming}
glimpse(daily_activity)
glimpse(sleep_day)
```

### 2.5 Converting activity_date and sleep_day from character to date format
Now it's time to change the activity_date column from character format to date format. I've decided to use the as.Date() function to convert the data into the correct format. 
```{r Formatting the activity_date column from character to date}
daily_activity$activity_date <- as.Date(daily_activity$activity_date, format = "%m/%d/%Y")
```

The sleep_day column, however, has an additional time component which will need to be removed before converting to date format. This can be taken care of with the gsub() function, nested within the as.Date() function.
```{r Formatting the sleep_day column from character to date}
sleep_day$sleep_day <- as.Date(gsub(" 12:00:00 AM.*", "", sleep_day$sleep_day), format = "%m/%d/%Y")
```

### 2.6 Converting user ids from number to string characters
Because the user ids are not numerical values, I decided to convert them to string characters for ease with later analysis.
```{r}
sleep_day$id<-as.character(sleep_day$id)
daily_activity$id<-as.character(daily_activity$id)
```

### 2.7 Combining the dataframes
Now that we have two dataframes with id and date columns, we can combine them. I decided to use a left join to combine the dataframes, retaining all the records from the daily_activity dataframe because it has more rows and therefore more data entries. These will be combined with the matching sleep_day data, if available. Keeping the daily_activity information without matching sleep_day data will provide us additional insight because it demonstrates that the device was used during the day, but not at night. 
```{r Combining the dataframes}
lj_combined <- left_join(daily_activity, sleep_day, by=c("id"="id", "activity_date"="sleep_day"))
```

Let's take a look at the new dataframe.
```{r}
glimpse(lj_combined)
```

It looks good so we can proceed onto the next step of our analysis.

# Step 3: Process
In this step, the data will be further cleaned and transformed in preparation for analyzation.

### 3.1 Create new active_minutes column
There are three columns with active minutes (very_active_minutes, fairly_active_minutes, lightly_active_minutes) so I have decided to combine them into one "active_minutes" column to make the table more succinct.
```{r Create new ActiveMinutes column}
lj_combined <- mutate(lj_combined, active_minutes = very_active_minutes + fairly_active_minutes + lightly_active_minutes)
```

##### 3.1.1 Delete the three divided active minutes columns
Now that I have a new active minutes column, I can delete the three divided active minutes columns. 
```{r Delete divided active minutes column}
lj_combined <- lj_combined [, -c(11:13)]
```

### 3.2 Create new day_of_week column
In general, most people tend to work Monday through Friday, which can affect their activity levels. Therefore, it may be useful to look at weekday vs. weekend data to see if the days of the week have an affect on smart device use. 

#### 3.2.1 Loading lubridate package
In order to use the function I want, I need to install and load the lubridate package.
```{r Loading the lubridate package}
library(lubridate)
```

#### 3.2.2 Creating the day_of_week column
```{r Creating new day_of_week column}
lj_combined$day_of_week = c(wday(lj_combined$activity_date, label=TRUE))
```

#### 3.2.3 Reordering the dataframe to put day_of_week after activity_date
Because day_of_week is determined from the date, it is best to have these columns next to each other. 
```{r Reordering the dataframe}
lj_combined <- lj_combined[, c(1,2,17,3,4,5,6,7,8,9,10,16,11,12,13,14,15)]
```
While I was reordering the data, I also moved the active_minutes column to appear prior to the sedentary_minutes column. 

### 3.3 Converting minutes to hours
I am converting the minutes to hours because we typically think of time in hours when the number of minutes is in the hundreds. 
```{r Converting minutes to hours}
lj_combined <- mutate(lj_combined, active_hours = active_minutes/60, sedentary_hours = sedentary_minutes/60, total_hours_asleep = total_minutes_asleep/60, total_time_in_bed = total_time_in_bed/60)
```

#### 3.3.1 Deleting the minutes column and reordering the dataframe
Now that I have the new hours columns, I can delete the minutes columns and reorder the remaining columns.
```{r}
lj_combined <- lj_combined [, c(1,2,3,4,5,6,7,8,9,10,11,18,19,14,15,20,17)]
```

Now that the data has been cleaned and transformed let's take a look at the finalized dataframe before we start our analysis. 
```{r}
glimpse(lj_combined)
```

The dataframe looks good so we can proceed to the next step. 

# Step 4: Analyze
In this step, we will look at some basic statistics from the dataset and other numbers to find trends and relationships in the data. We will also be creating a couple simple tables to get a different perspective of the same information. 

### 4.1 Using the summary function to look at generic statistics of the dataset
The summary function will give me a better idea of the distribution of the variables in my dataset. I picked a few of the variables that I felt were the most interesting. 
```{r Summary of the dataframe}
lj_combined %>% 
  select(day_of_week, total_steps, tracker_distance, logged_activities_distance, active_hours, sedentary_hours, calories, total_sleep_records, total_hours_asleep, total_time_in_bed) %>% 
  summary()
```
There are a few interesting insights to gain from this summary of the dataset. 

1. The mean total_steps was 7,652 which is below the [CDC](https://www.cdc.gov/diabetes/prevention/pdf/postcurriculum_session8.pdf) recommended 10,000 of steps per day.
2. The mean logged_activities_distance was 0.110 versus the mean tracker_distance which was 5.489, demonstrating that users are mostly passively using the devices to log their activities. 
3. According to the [2015-2020 Dietary Guidelines for Americans](https://health.gov/sites/default/files/2019-09/2015-2020_Dietary_Guidelines.pdf), women are likely to need to intake an average of 2,000 calories per day, men 2,500 calories per day. The mean calories burned for this dataset is 2,308, nearly in the middle of the recommended intake of calories for both genders. Assuming users are consuming the recommended calories, it would seem they are not using the devices to lose weight, as each pound of fat accounts for 3,500 calories. 
4. The top three days of the week with the most records are in order, Tuesday, Wednesday, and Thursday, demonstrating that device use is most active mid-week. 
5. There are 530 NA's for the sleep data. Because there are 943 total records, that means the devices are being used less than half the time at night. 

### 4.2 Count unique users in the dataset
Per the dataset source, there is data from thirty eligible users, but it is important (and simple) to confirm the number of users.

```{r Count unique users}
n_distinct(lj_combined$id)
```

By running this chunk, it is revealed that there are actually thirty-three unique users, not thirty as stated by the dataset author. This will be important to remember in later analysis, when we look at averages amongst the users. 

### 4.3 Daily device usage - full vs. partial data
I also thought it was important to look at how often users were actually using their devices throughout the whole day. In order to make this determination, I chose to look at the number of active_hours plus the number of sedentary_hours that added up to 24 as well as those that did not add up to 24 because there are 24 hours in a day. 
```{r Full vs. partial data per day}
sum(lj_combined$active_hours + lj_combined$sedentary_hours == 24)
sum(lj_combined$active_hours + lj_combined$sedentary_hours != 24)
```

This reveals that 478 out of 943 records have data for the full day and 465 records have data for part of the day. Therefore, about half the time users are not using the device all day. This is likely related to the fact that there are about 530 records that are missing sleep data and users are not consistently using the devices to track sleep. 

It is also interesting to note that there are 530 entries that are missing sleep data, but only 465 entries with partial data. This demonstrates that the devices may not always be properly recording sleep data. 

### 4.4 Average calories by id

While an overall calories per day average (2,308) is useful to know, the typical activity level of each individual can vary greatly and combine to make an average that looks unremarkable. Because of this, I thought it would be important to look at the calorie averages per day by id. I decided to create a new dataframe for this information, which we can later use during visualization. 
```{r Creating a new table for average calories per id}
avg_calories_per_id<-lj_combined %>% 
  group_by(id) %>% 
  summarize_at(vars(calories), list(avg_calories=mean))
```

Here's a look at the first few entries of the new dataframe.
```{r Looking at avg_calories_per_id dataframe}
head(avg_calories_per_id)
```

### 4.5 Average calories by day of week
Because of my theory about weekday versus weekend calorie differentials, I felt it would be important to examine average calories per day of week as well. Therefore I created another dataframe with this information, also for use during analysis. 
```{r Creating a new table for average calories per day of week}
avg_calories_per_day_of_week<-lj_combined %>% 
  group_by(day_of_week) %>% 
  summarize_at(vars(calories), list(avg_calories=mean))
```

And here's a look at the new dataframe. 
```{r Looking at calories_per_day_of_week dataframe}
head(avg_calories_per_day_of_week, n=7)
```


# Step 5: Share
In this step, visualizations will be created to demonstrate insights from the dataset, which will help lead us to make recommendations to the company. 

### 5.1 Count by day of the week
The typical work week is Monday through Friday and most people are spending eight hours a day at work, leaving less free time to exercise on those days. Therefore, I thought it would be important to examine device usage to see if people tended to use them on weekdays versus weekends. 
```{r Records by day of the week}
ggplot(lj_combined, mapping=aes(x=day_of_week, fill=..count..))+
  geom_bar(width=0.7, stat="count")+
  scale_fill_gradient(low="blue", high="red")+
  geom_text(stat="count", aes(label=..count..), vjust=-.25)+
  labs(title="Records per Day of Week", x="Day of the Week", y="Count")
```

This bar graph demonstrates that device usage is highest on Tuesday, Wednesday, and Thursday, in that order. While there is no certainty as to why usage in highest mid-week, it may indicate that devices are being used to look at activity levels on workdays so users can be aware to try to increase activity if they are falling short of their goals, which is more likely when a large portion of their day is devoted to work.

### 5.2 Average Calories per Day of Week
This prompts me to look at the average calories per day of week, on the assumption of a typical Monday through Friday workweek with a weekends on Saturdays and Sundays. 
```{r Visualization for average calories per day}
ggplot(avg_calories_per_day_of_week, mapping=aes(x=day_of_week, y=avg_calories, group=1))+
  geom_col(fill="darkgray")+
  geom_line(color="red", size=1)+
  labs(title="Average Calories per Day", x="Day of the Week", y="Calories")
```

This visualization shows that there is relatively little variation in the average amount of calories burned per day of week. Therefore, it doesn't seem that users are discriminating between workdays and weekends in regards to their calories burned and it perhaps isn't a good marketing angle to use. 

### 5.3 Examining logged activities distance and tracked distance
There is an option for users to log activities, but the device also passively tracks distance for users. Looking at the data for these two variables can help determine how users tend to use the devices. 

```{r Visualization for logged and tracked activities distance}
ggplot(lj_combined, mapping=aes(x=tracker_distance, y=logged_activities_distance))+
  geom_point(color="blue")+
  labs(title="Logged vs. Tracked Activity Distance")
``` 
  
This chart demonstrates that users are generally passive in regards to tracking distance. The majority of the time users have not logged in any distances, however the tracker has been passively keeping track of the users distance.

Looking at this chart, it would be interesting to see how many "0" entries there are for logged distance because they are all muddled at the bottom of the chart. 

```{r Determining how many records have 0 for logged distance}
nrow(subset(lj_combined, logged_activities_distance == 0))
```
Out of 943 entries, there are 910 times that the logged_activities_distance was 0. Users are logging activity very infrequently - in fact, only about 3.5% of the records have logged activity. It may be useful to market to users that the devices track activities passively as it seems to be the preferred means of this user group. 

### 5.4
As mentioned previously, the typical activity level of each individual can vary greatly and combine to make an average that looks unremarkable. Therefore, I previously created a table with average calories per user id. Now we can look at the data from that table. 
```{r}
ggplot(avg_calories_per_id, mapping=aes(x=id, y=avg_calories))+
  geom_col(fill="darkgray")+
  geom_hline(aes(yintercept=2000, color="red"), linetype=2, color="red", size=1)+
  geom_hline(aes(yintercept=2500, color = "blue"), linetype=2, color="blue", size=1)+
  geom_hline(aes(yintercept=2308, color="purple"), linetype=1, color="purple", size=1)+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  labs(title="Average Calories per User", x="Users", y="Calories")
```

I added in a few horizontal lines to show how the user group compared with recommended calorie intakes for males (dashed blue line), females(dashed red line), and the overall average calories burned for the group (solid purple). Looking at the chart, most users are clearly falling short of burning the recommended calorie intake for males. However, it appears that most users are burning more than the recommended calorie intake for females. Here's a look at the actual numbers. 

```{r}
nrow(subset(avg_calories_per_id, avg_calories<2500))
nrow(subset(avg_calories_per_id, avg_calories<2000))
```
Insights: 

1. 21 out of 33, 63.6% of users are burning less than the recommended calorie intake for males. 
2. 13 out of 33, 39.3% of users are burning less than the recommended calorie intake for females. 

If users are consuming around the recommended number of calories, most are not likely using the devices to lose weight. A majority of them are burning less than the recommended intake for males, and while not a majority, there is still a good percentage that is not burning the recommended calorie intake for females.  


